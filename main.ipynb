{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FEOXFeGjSe1v"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5ozr1ygMFvD",
        "outputId": "a03bbcdf-1c8f-438c-cda8-4f990de4dc8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                            song_id  artist_id  song_length  album_id  \\\n",
            "0  10a46165bb84e056438e06c35763ee61       39.0        202.0     202.0   \n",
            "1  10a46165bb84e056438e06c35763ee61       39.0        202.0     202.0   \n",
            "2  ff025522d0f8e7198a75a4e03edce55c      133.0        278.0    9615.0   \n",
            "3  ff025522d0f8e7198a75a4e03edce55c      133.0        278.0    9615.0   \n",
            "4  7feec55b825a1c93d55b3ef9af9f9be5     4147.0        306.0   19017.0   \n",
            "\n",
            "   language_id album_month                       composer_id  \\\n",
            "0          3.0     2000-01                               NaN   \n",
            "1          3.0     2000-01                               NaN   \n",
            "2          3.0     1995-01  47580d357c6779d6a244c514b0acdc72   \n",
            "3          3.0     1995-01  47580d357c6779d6a244c514b0acdc72   \n",
            "4          3.0     2015-06  3211cf51bfa3afff4f264a110212f615   \n",
            "\n",
            "                           genre_id                       lyricist_id  \\\n",
            "0  ce4db56f6a48426643b08038139a8a75                               NaN   \n",
            "1  b856b6781d370a3645c6dde0c20b3597                               NaN   \n",
            "2  ce4db56f6a48426643b08038139a8a75                               NaN   \n",
            "3  b856b6781d370a3645c6dde0c20b3597                               NaN   \n",
            "4  ce4db56f6a48426643b08038139a8a75  3211cf51bfa3afff4f264a110212f615   \n",
            "\n",
            "                        producer_id                     title_text_id  \n",
            "0  95584be121b41e3e758bd99e9cc07abd  b2153fe5a86fd746903746a219d40083  \n",
            "1  95584be121b41e3e758bd99e9cc07abd  b2153fe5a86fd746903746a219d40083  \n",
            "2  8e9704c1d8cf460fe5a2eb4470e77d3e  c1079ef109db2aba72f78c632ab73803  \n",
            "3  8e9704c1d8cf460fe5a2eb4470e77d3e  c1079ef109db2aba72f78c632ab73803  \n",
            "4  086136ec34f3ff6eb89cfa7c446bd69f  c1079ef109db2aba72f78c632ab73803  \n"
          ]
        }
      ],
      "source": [
        "# 讀取meta的各個檔案\n",
        "composer_df = pd.read_parquet('data/meta_song_composer.parquet')\n",
        "song_df = pd.read_parquet('data/meta_song.parquet')\n",
        "genre_df = pd.read_parquet('data/meta_song_genre.parquet')\n",
        "lyricist_df = pd.read_parquet('data/meta_song_lyricist.parquet')\n",
        "producer_df = pd.read_parquet('data/meta_song_producer.parquet')\n",
        "titletext_df = pd.read_parquet('data/meta_song_titletext.parquet')\n",
        "\n",
        "# 將資料以 song_id 作為主體合併\n",
        "merged_df = pd.merge(song_df, composer_df, on='song_id', how='left')\n",
        "merged_df = pd.merge(merged_df, genre_df, on='song_id', how='left')\n",
        "merged_df = pd.merge(merged_df, lyricist_df, on='song_id', how='left')\n",
        "merged_df = pd.merge(merged_df, producer_df, on='song_id', how='left')\n",
        "merged_df = pd.merge(merged_df, titletext_df, on='song_id', how='left')\n",
        "meta_merged_df = merged_df.copy()\n",
        "\n",
        "# 顯示合併後的 DataFrame\n",
        "print(meta_merged_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n75vG3PRNY16",
        "outputId": "3ec629dc-1aae-46da-fb5c-3ccabfb51956"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "song_id                0\n",
              "artist_id         185318\n",
              "song_length       185318\n",
              "album_id          401967\n",
              "language_id       401967\n",
              "album_month       402019\n",
              "composer_id       726444\n",
              "genre_id          403030\n",
              "lyricist_id      1299883\n",
              "producer_id      1579454\n",
              "title_text_id     185318\n",
              "dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "merged_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAkC7FdISe1y"
      },
      "outputs": [],
      "source": [
        "# 加载数据\n",
        "label_train_source = pd.read_parquet('data/label_train_source.parquet')\n",
        "label_train_target = pd.read_parquet('data/label_train_target.parquet')\n",
        "label_test_source = pd.read_parquet('data/label_test_source.parquet')\n",
        "\n",
        "# 标签编码\n",
        "song_encoder = LabelEncoder()\n",
        "all_songs = pd.concat([label_train_source['song_id'], label_train_target['song_id'], label_test_source['song_id']]).unique()\n",
        "song_encoder.fit(all_songs)\n",
        "\n",
        "# 将歌曲ID转换为数值\n",
        "label_train_source['song_id'] = song_encoder.transform(label_train_source['song_id'])\n",
        "label_train_target['song_id'] = song_encoder.transform(label_train_target['song_id'])\n",
        "label_test_source['song_id'] = song_encoder.transform(label_test_source['song_id'])\n",
        "\n",
        "# 数据清洗和预处理（例如去重、排序等）\n",
        "# 去重\n",
        "# label_train_source.drop_duplicates(inplace=True)\n",
        "# label_train_target.drop_duplicates(inplace=True)\n",
        "# label_test_source.drop_duplicates(inplace=True)\n",
        "\n",
        "# 排序\n",
        "# label_train_source.sort_values(by=['session_id', 'unix_played_at'], inplace=True)\n",
        "# label_train_target.sort_values(by=['session_id', 'unix_played_at'], inplace=True)\n",
        "# label_test_source.sort_values(by=['session_id', 'unix_played_at'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mEfkF2xylSK",
        "outputId": "c5229823-563d-4c21-d120-a6df8686a7ea"
      },
      "outputs": [],
      "source": [
        "print(\"train source\\n\",label_train_source.head())\n",
        "print(\"=====================================================================================================\")\n",
        "print(\"train target\\n\",label_train_source.head())\n",
        "print(\"=====================================================================================================\")\n",
        "print(\"test source\\n\",label_train_source.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVqoakPvSe1z"
      },
      "outputs": [],
      "source": [
        "def create_sequences_optimized(df_source, df_target, sequence_length=20):\n",
        "    # 确保数据是按session_id和播放时间排序的\n",
        "    df_source = df_source.sort_values(by=['session_id', 'unix_played_at'])\n",
        "    df_target = df_target.sort_values(by=['session_id', 'unix_played_at'])\n",
        "\n",
        "    # 使用groupby和agg来构建序列\n",
        "    X = df_source.groupby('session_id')['song_id'].agg(list)\n",
        "    y = df_target.groupby('session_id')['song_id'].agg(list)\n",
        "\n",
        "    # 过滤出符合条件的序列\n",
        "    X_filtered = X[X.apply(len) == sequence_length]\n",
        "    y_filtered = y[y.apply(len) == 5]\n",
        "\n",
        "    # 保留两个数据集都有的session_id\n",
        "    common_sessions = X_filtered.index.intersection(y_filtered.index)\n",
        "    X_final = X_filtered.loc[common_sessions].tolist()\n",
        "    y_final = y_filtered.loc[common_sessions].tolist()\n",
        "\n",
        "    return np.array(X_final), np.array(y_final)\n",
        "\n",
        "X_train, y_train = create_sequences_optimized(label_train_source, label_train_target)\n",
        "X_test = label_test_source.groupby('session_id').apply(lambda x: x['song_id'].values if len(x) == 20 else None).dropna().values\n",
        "\n",
        "# 将目标数据（y_train）转换为独热编码，因为我们的模型将进行多分类任务\n",
        "# onehot_encoder = OneHotEncoder(sparse_output=True, categories=[np.arange(len(all_songs))])\n",
        "# y_train_onehot = onehot_encoder.fit_transform(y_train.reshape(-1, 1))\n",
        "# # 将稀疏矩阵转换为密集数组\n",
        "# y_train_dense = y_train_onehot.toarray()\n",
        "\n",
        "# 假设每个序列的最后一个目标是我们要预测的目标\n",
        "# y_train 是一个二维数组，其中每个子数组包含5个类别索引\n",
        "y_train_last = [targets[-1] for targets in y_train]  # 取每个序列的最后一个目标\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDouOvfTBtoI",
        "outputId": "0a7c00db-0cc9-4b72-d952-6e97887404ce"
      },
      "outputs": [],
      "source": [
        "# 将数据转换为PyTorch张量\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.long)\n",
        "y_train_tensor = torch.tensor(y_train_last, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(list(X_test), dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmJw3gaSSe1z"
      },
      "outputs": [],
      "source": [
        "class MusicPredictionModel(nn.Module):\n",
        "    def __init__(self, num_songs, embedding_dim=50, lstm_units=64, num_heads=2, dropout=0.2):\n",
        "        super(MusicPredictionModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(num_songs, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, lstm_units, batch_first=True)\n",
        "        self.attention = nn.MultiheadAttention(lstm_units, num_heads, dropout=dropout)\n",
        "        self.fc = nn.Linear(lstm_units, num_songs)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)  # (batch_size, seq_length, embedding_dim)\n",
        "        lstm_out, _ = self.lstm(embedded)  # (batch_size, seq_length, lstm_units)\n",
        "        attn_output, _ = self.attention(lstm_out, lstm_out, lstm_out)  # (batch_size, seq_length, lstm_units)\n",
        "        out = self.fc(attn_output[:, -1, :])  # 取序列最后一个时间步的输出\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKnhP2L5C01V",
        "outputId": "09b110b7-8950-42e6-fda5-622108069190"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is available.\")\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print(\"GPU is not available, using CPU.\")\n",
        "    device = torch.device(\"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2UCIm2HSe10",
        "outputId": "6e9b8a2d-dbcb-4b9b-b31a-abf790dc10f1"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, epochs=10, lr=0.001):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader)}')\n",
        "    \n",
        "    torch.save(model.state_dict(), 'model.pth')\n",
        "\n",
        "\n",
        "# 创建数据加载器\n",
        "train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# 实例化模型并训练\n",
        "num_songs = len(all_son_songs)\n",
        "model = MusicPredictionModel(num_songs).to(device)\n",
        "train(model, train_loader, 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjL0t45GSe10"
      },
      "outputs": [],
      "source": [
        "def predict(model, trained_pth, test_loader):\n",
        "    model.eval()\n",
        "    model.load_state_dict(torch.load(trained_pth))\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for inputs in test_loader:\n",
        "            outputs = model(inputs).to(device)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# 创建测试数据加载器\n",
        "test_loader = torch.utils.data.DataLoader(X_test_tensor, batch_size=32)\n",
        "\n",
        "# 进行预测\n",
        "predictions = predict(model, 'model.pth', test_loader)\n",
        "\n",
        "# 保存预测结果为CSV\n",
        "predicted_songs = song_encoder.inverse_transform(predictions)\n",
        "pd.DataFrame(predicted_songs, columns=['predicted_song_id']).to_csv('predictions.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
